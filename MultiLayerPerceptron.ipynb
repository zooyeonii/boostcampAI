{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "266510f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version:[1.8.1].\n",
      "device:[cuda:0].\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"device:[%s].\"%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c1866",
   "metadata": {},
   "source": [
    "gpu를 잘 쓰고 있군요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e5713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_train:\n",
      " Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      "mnist_test:\n",
      " Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data/\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor() \n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "mnist_train = datasets.MNIST(root='./data/', train=True, transform = transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root = './data/', train=False, transform = transforms.ToTensor(), download=True)\n",
    "print(\"mnist_train:\\n\", mnist_train, \"\\n\")\n",
    "print(\"mnist_test:\\n\", mnist_test, \"\\n\")\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a618de",
   "metadata": {},
   "source": [
    "### Data Iterator\n",
    "#### DataLoader(dataset, batch_size, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa304e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n",
    "print (\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cb38e",
   "metadata": {},
   "source": [
    "### MLP model\n",
    "#### torch.nn.Linear(in_feat, out_feat, bias=True, device=None, dtype = None)\n",
    "1. in_features : input sample의 size \n",
    "2. out_features : output sample의 size \n",
    "3. bias = False이면, layer는 bias를 학습하지 않는다. default는 True이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f764dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptronClass(nn.Module):\n",
    "    def __init__(self, name='mlp', xdim=784, hdim=256, ydim=10):\n",
    "        super(MultiLayerPerceptronClass, self).__init__()\n",
    "        self.name = name\n",
    "        self.xdim = xdim\n",
    "        self.hdim = hdim\n",
    "        self.ydim = ydim\n",
    "        self.lin_1 = nn.Linear(self.xdim, self.hdim, device)\n",
    "        self.lin_2 = nn.Linear(self.hdim, self.ydim, device)\n",
    "        self.init_param() \n",
    "        \n",
    "    def init_param(self):\n",
    "        nn.init.kaiming_normal_(self.lin_1.weight)\n",
    "        nn.init.zeros_(self.lin_1.bias)\n",
    "        nn.init.kaiming_normal_(self.lin_2.weight)\n",
    "        nn.init.zeros_(self.lin_2.bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        net = x\n",
    "        net = self.lin_1(net)\n",
    "        net = F.relu(net)\n",
    "        net = self.lin_2(net)\n",
    "        return net\n",
    "    \n",
    "model = MultiLayerPerceptronClass(name='mlp',xdim=784,hdim=256,ydim=10).to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optm = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "073dbe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLayerPerceptronClass(\n",
      "  (lin_1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (lin_2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83118955",
   "metadata": {},
   "source": [
    "### Forward Path of the MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98df70e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_numpy:\n",
      " [[0.94285789 0.20773299 0.04822789 ... 0.04476771 0.81844804 0.86634775]\n",
      " [0.19317892 0.34745886 0.39895159 ... 0.58484288 0.94875307 0.13006104]]\n",
      "x_torch:\n",
      " tensor([[0.9429, 0.2077, 0.0482,  ..., 0.0448, 0.8184, 0.8663],\n",
      "        [0.1932, 0.3475, 0.3990,  ..., 0.5848, 0.9488, 0.1301]],\n",
      "       device='cuda:0')\n",
      "y_torch:\n",
      " tensor([[-1.3884,  1.1287, -0.2183, -0.3486,  1.2217, -0.0940, -1.2542, -0.2093,\n",
      "         -0.7002,  1.3421],\n",
      "        [-0.6304,  0.7817, -0.9152, -0.5888,  1.5725, -0.0132, -1.8734, -0.5062,\n",
      "         -0.6180,  1.1436]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "y_numpy:\n",
      " [[-1.3883781   1.128686   -0.2182925  -0.34859407  1.2216712  -0.09404826\n",
      "  -1.2541772  -0.2093036  -0.7002028   1.3420562 ]\n",
      " [-0.63035476  0.78171146 -0.91522765 -0.5887705   1.5724785  -0.01320729\n",
      "  -1.8733902  -0.50616753 -0.6179874   1.1436275 ]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "x_numpy = np.random.rand(2, 784)\n",
    "x_torch = torch.from_numpy(x_numpy).float().to(device)\n",
    "y_torch = model.forward(x_torch) #forward 후 출력되는 y class\n",
    "y_numpy = y_torch.detach().cpu().numpy() # tensor to numpy\n",
    "print(\"x_numpy:\\n\", x_numpy)\n",
    "print(\"x_torch:\\n\", x_torch)\n",
    "print(\"y_torch:\\n\", y_torch)\n",
    "print(\"y_numpy:\\n\", y_numpy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228677c2",
   "metadata": {},
   "source": [
    "### Check Parameters\n",
    "#### weight, bias of each layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ac7e2",
   "metadata": {},
   "source": [
    "np.set_printoptions(precision=None, threshold=None, ...): precision : output 소수점 아래 자리를 고정하기 위해 사용함. \n",
    "#### Parameter를 확인하는 방법 2가지\n",
    "1. torch.nn.Module.parameters() : layer 이름을 제외한 parameter 값에 대한 iterator를 리턴함  \n",
    "2. torch.nn.Module.named_parameters() : (parameter name, parameter)의 튜플 iterator 리턴함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6a238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] name:[lin_1.weight] shape: [(256, 784)].\n",
      "   val:[-0.055  0.104 -0.032  0.041  0.089]\n",
      "[1] name:[lin_1.bias] shape: [(256,)].\n",
      "   val:[0. 0. 0. 0. 0.]\n",
      "[2] name:[lin_2.weight] shape: [(10, 256)].\n",
      "   val:[-0.08   0.032 -0.062 -0.045  0.055]\n",
      "[3] name:[lin_2.bias] shape: [(10,)].\n",
      "   val:[0. 0. 0. 0. 0.]\n",
      "Total number of parameters:[203,530].\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "n_param = 0\n",
    "for p_idx, (param_name, param) in enumerate(model.named_parameters()):\n",
    "    param_numpy = param.detach().cpu().numpy()\n",
    "    n_param += len(param_numpy.reshape(-1))\n",
    "    print(\"[%d] name:[%s] shape: [%s].\"%(p_idx, param_name, param_numpy.shape))\n",
    "    print(\"   val:%s\"%(param_numpy.reshape(-1)[:5]))\n",
    "print(\"Total number of parameters:[%s].\"%(format(n_param, ',d')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5fe06e",
   "metadata": {},
   "source": [
    "### Evaluation Function\n",
    "torch.Tensor는 .require_grad 속성을 True로 설정하면, 그 tensor에서 이뤄진 모든 연산을 추적한다. 따라서 계산이 완료된 후 .backward()를 호출하면 모든 gradient를 자동으로 계산할 수 있다. 이 변화도는 .grad 에 누적된다. \n",
    "1. with torch.no_grad() : 메모리 사용량을 줄이기 위해 코드 블럭을 감싼 것이다. 평가하는 단게에서는 gradient를 계산할 필요가 없기 때문이다. \n",
    "\n",
    "train 과 evalute에 서로 다르게 동작해야 하는 것 : 1) Dropout layer, 2) BatchNorm layer\n",
    "\n",
    "2. model.eval() : evaluation 과정에서 사용하지 않아야 할 layer를 알아서 off 시키는 역할을 한다. evaluation이 끝나면 다시 model.train()을 통해 train mode로 변경 해줘야 한다. \n",
    "3. data_iter : test_set image (=batch_in), label (=batch_out)\n",
    "4. torch.max(input tensor, dim to reduce) : input tensor는 batch의 각 y class이다. 각각에서 max값을 1-dim tensor로 리턴한다._은 가장 큰 확률 값 텐서이고, y_pred는 argmax idx이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6eb40ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def func_eval(model, data_iter, device):\n",
    "    with torch.no_grad():\n",
    "        model.eval() \n",
    "        n_total, n_correct = 0, 0\n",
    "         \n",
    "        for batch_in, batch_out in data_iter:\n",
    "            label = batch_out.to(device)\n",
    "            # model 안에 test set을 넣고 예측을 출력\n",
    "            model_pred = model.forward(batch_in.view(-1, 28*28).to(device))\n",
    "            \n",
    "            _, y_pred = torch.max(model_pred.data, 1)\n",
    "            n_correct += (y_pred == label).sum().item()\n",
    "            n_total += batch_in.size(0)\n",
    "        val_accr = (n_correct/n_total)\n",
    "        model.train()\n",
    "    return val_accr\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f51febf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1914, -0.2675,  1.7128, -0.0170, -0.1897],\n",
       "        [ 1.2396,  2.1350,  0.6858,  0.9363, -0.4073],\n",
       "        [ 1.8576, -0.5630, -0.6915,  0.0913,  0.9568],\n",
       "        [ 0.2810, -0.4587, -0.2019,  0.6088,  0.3123]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4,5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e3b5077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1.7128, 2.1350, 1.8576, 0.6088]),\n",
       "indices=tensor([2, 1, 0, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(a, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa57a1f",
   "metadata": {},
   "source": [
    "### Initial Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06d12bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_accr:[0.085] test_accr:[0.082].\n"
     ]
    }
   ],
   "source": [
    "model.init_param()\n",
    "train_accr = func_eval(model, train_iter, device)\n",
    "test_accr = func_eval(model, test_iter, device)\n",
    "print(\"train_accr:[%.3f] test_accr:[%.3f].\"%(train_accr, test_accr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1679e0",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a83d1fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:[0] loss:[0.380] train_accr:[0.947] test_accr:[0.946].\n",
      "epoch:[1] loss:[0.163] train_accr:[0.966] test_accr:[0.961].\n",
      "epoch:[2] loss:[0.115] train_accr:[0.975] test_accr:[0.968].\n",
      "epoch:[3] loss:[0.087] train_accr:[0.981] test_accr:[0.972].\n",
      "epoch:[4] loss:[0.069] train_accr:[0.983] test_accr:[0.974].\n",
      "epoch:[5] loss:[0.056] train_accr:[0.988] test_accr:[0.974].\n",
      "epoch:[6] loss:[0.046] train_accr:[0.990] test_accr:[0.979].\n",
      "epoch:[7] loss:[0.039] train_accr:[0.992] test_accr:[0.980].\n",
      "epoch:[8] loss:[0.033] train_accr:[0.995] test_accr:[0.980].\n",
      "epoch:[9] loss:[0.027] train_accr:[0.996] test_accr:[0.980].\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "model.init_param()\n",
    "model.train()\n",
    "EPOCHS, print_every = 10, 1\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_sum = 0\n",
    "    for batch_in, batch_out in train_iter:\n",
    "        y_pred = model.forward(batch_in.view(-1, 28*28).to(device))\n",
    "        loss_out = loss(y_pred, batch_out.to(device))\n",
    "        \n",
    "        optm.zero_grad()\n",
    "        loss_out.backward()\n",
    "        optm.step()\n",
    "        \n",
    "        loss_sum += loss_out\n",
    "    loss_avg = loss_sum/len(train_iter)\n",
    "    \n",
    "    if ((epoch%print_every)==0) or (epoch==(EPOCHS-1)):\n",
    "        train_accr = func_eval(model,train_iter,device)\n",
    "        test_accr = func_eval(model,test_iter,device)\n",
    "        print (\"epoch:[%d] loss:[%.3f] train_accr:[%.3f] test_accr:[%.3f].\"%\n",
    "               (epoch,loss_avg,train_accr,test_accr))\n",
    "print (\"Done\")    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042c0989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tt",
   "language": "python",
   "name": "tt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
